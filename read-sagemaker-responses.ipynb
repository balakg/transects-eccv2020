{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import jsonlines\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['ffhq', 'stylegan2', 'celeba-hq', 'transects']\n",
    "dataset = datasets[3] #stylegan2-latents' # or celeba-hq or ffhq or transect\n",
    "BASE_DIR = './datasets/%s/' % dataset\n",
    "ANNOTATIONS_DIR = BASE_DIR + 'sagemaker/'\n",
    "LABELS_FILE = '/annotation-tool/data.json'\n",
    "OUT_MANIFEST_FILE = '/manifests/output/output.manifest'\n",
    "WORKERS_RESPONSE = '/annotations/worker-response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class annotationDatabase():\n",
    "    \n",
    "    def __init__(self,annotations_file_names, labelScores):\n",
    "        '''Parameters:\n",
    "        annotations_file_names - list of names of jupyter files where the annotations are saved.\n",
    "        Each file refers to one image.'''\n",
    "        self.annotators = {}           # dictionary that maps the unique ID strings of annotators to local integer IDs\n",
    "        self.annotator_names = []      # list of the unique string identifiers that AMT uses sorted by integer ID\n",
    "        self.annotations = []          # list of the number of annotations per annotator\n",
    "        self.N_ANNOTATORS = len(self.annotators)\n",
    "        self.N_IMAGES = len(annotations_file_names)\n",
    "        self.imageScores = []          # scores this image received -- list of lists\n",
    "        self.imageAnnotators = []      # annotators who worked on a given image -- list of lists\n",
    "        \n",
    "        #\n",
    "        # for each file extract all the useful annotations\n",
    "        #\n",
    "        for i, fname in enumerate(annotations_file_names):\n",
    "            with open(fname, 'r') as read_file:\n",
    "                data = json.load(read_file)                  # open the json file and read its contents into data\n",
    "                scores = []                                  # initialize the two lists of scores and IDs for the current image\n",
    "                annotatorIDs = []\n",
    "                for a,ans in enumerate(data['answers']):     # read each annotator's annotation\n",
    "                    ID = self.addAnnotation(ans['workerId']) # mark annotation and retrieve ID of annotator\n",
    "                    annotatorIDs.append(ID)                  # take note of which annotator it was\n",
    "                    label = data['answers'][a]['answerContent']['crowd-image-classifier']['label']\n",
    "                    scores.append(labelScores[label]) # transform label into score\n",
    "                    \n",
    "                self.imageScores.append(scores)\n",
    "                self.imageAnnotators.append(annotatorIDs)\n",
    "        \n",
    "        print(f'Found {self.N_IMAGES} images and {self.N_ANNOTATORS} annotators.')\n",
    "        \n",
    "    def addAnnotation(self,annotator_name):\n",
    "        '''Keep track of the annotations and of the annotators'''\n",
    "        try:\n",
    "            ID = self.annotators[annotator_name] # the annotator was found, here is her ID\n",
    "            self.annotations[ID] += 1 # chalk up one more annotation for this annotator\n",
    "        except: # the annotator was not on the list\n",
    "            ID = self.N_ANNOTATORS # create a new ID\n",
    "            self.annotators[annotator_name] = ID\n",
    "            self.N_ANNOTATORS +=1\n",
    "            self.annotations.append(1) # add a count of one for the last annotator\n",
    "            self.annotator_names.append(annotator_name)\n",
    "        return ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "Found 8000 images and 590 annotators.\n",
      "facial-hair\n",
      "Found 8000 images and 480 annotators.\n",
      "gender\n",
      "Found 8000 images and 559 annotators.\n",
      "hair-length\n",
      "Found 8000 images and 514 annotators.\n",
      "makeup\n",
      "Found 8000 images and 484 annotators.\n",
      "skin-color\n",
      "Found 8000 images and 489 annotators.\n",
      "smile\n",
      "Found 8000 images and 534 annotators.\n",
      "uncanny\n",
      "Found 8000 images and 587 annotators.\n"
     ]
    }
   ],
   "source": [
    "# Get list of attributes in annotation dir. Alternatively, specify ones you care about.\n",
    "attributes = [os.path.split(f)[1] for f in glob.glob(os.path.join(ANNOTATIONS_DIR, '*'))]\n",
    "attributes.sort()\n",
    "\n",
    "all_scores = []\n",
    "all_labels = []\n",
    "\n",
    "for attribute_label in attributes:\n",
    "    \n",
    "    print(attribute_label)\n",
    "    \n",
    "    ANNOTATIONS_PATH = f'{ANNOTATIONS_DIR}/{attribute_label}{WORKERS_RESPONSE}'\n",
    "    OUT_MANIFEST_PATH = f'{ANNOTATIONS_DIR}/{attribute_label}{OUT_MANIFEST_FILE}'\n",
    "    LABELS_PATH = f'{ANNOTATIONS_DIR}/{attribute_label}{LABELS_FILE}'\n",
    "\n",
    "    #Read labels using annotation-tool/data.json and assign integers to labels \n",
    "    with open(LABELS_PATH, 'r') as labels_file:\n",
    "        labels_data = json.load(labels_file)['labels']\n",
    "        LABELS = [l['label'] for l in labels_data]\n",
    "    labelScores = {l:i for (i, l) in enumerate(LABELS)} # generate numerical scores for the labels - useful in regression\n",
    "    all_labels.append(LABELS)\n",
    "    \n",
    "    # Make map from annotation index to image index\n",
    "    idx_map = []\n",
    "    with jsonlines.open(OUT_MANIFEST_PATH) as reader:\n",
    "        for obj in reader:\n",
    "            _, name = os.path.split(obj['source-ref']) #remove leading path\n",
    "            idx = name.split('.')[0]\n",
    "            idx_map.append(idx)\n",
    "\n",
    "    # Note: This loop assumes alphanumeric order = numeric order, e.g., file names are 0000.jpg, 0001.jpg, etc.)\n",
    "    annotation_file_names = []\n",
    "    for i in range(len(idx_map)):\n",
    "        annotation_file_names += glob.glob(ANNOTATIONS_PATH + '/*/%d/*.json'% i)\n",
    "    \n",
    "    # put together the database of the annotator IDs and their work\n",
    "    annotations = annotationDatabase(annotation_file_names, labelScores)\n",
    "    all_scores.append(np.array(annotations.imageScores))\n",
    "    \n",
    "# Save\n",
    "dic = {'attributes': attributes, 'responses': all_scores, 'attribute_levels': all_labels}\n",
    "pickle.dump(dic, open(BASE_DIR + 'annotations.pkl', 'wb'))\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
